{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwaYdk5A/GGvEoOrTOJoUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofinvalery/ml-notebooks/blob/main/inline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRr2lY5NC1vW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('meatinfo.csv', sep=';')\n",
        "\n",
        "product_counts = df['mtype'].value_counts()\n",
        "filtered_products = product_counts[product_counts >= 500].index.tolist()\n",
        "\n",
        "df_filtered = df[df['mtype'].isin(filtered_products)]\n",
        "\n",
        "train_df, test_df = train_test_split(df_filtered, test_size=0.2, stratify=df_filtered['mtype'], random_state=42)"
      ],
      "metadata": {
        "id": "taYnXhgOC3yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_len = 64\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_df['mtype'])\n",
        "test_labels = le.transform(test_df['mtype'])\n",
        "\n",
        "train_dataset = TextDataset(\n",
        "    texts=train_df['text'].tolist(),\n",
        "    labels=train_labels,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        ")\n",
        "\n",
        "test_dataset = TextDataset(\n",
        "    texts=test_df['text'].tolist(),\n",
        "    labels=test_labels,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "class MeatClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(MeatClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )['pooler_output']\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n",
        "\n",
        "n_classes = len(le.classes_)\n",
        "\n",
        "model = MeatClassifier(n_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQWpUmQODWZA",
        "outputId": "6fb08839-54f0-4bf2-8e17-4d3517b283d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        labels = d['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        correct_predictions += torch.sum(torch.argmax(outputs, dim=1) == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, criterion, device):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_mask = d['attention_mask'].to(device)\n",
        "            labels = d['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            correct_predictions += torch.sum(torch.argmax(outputs, dim=1) == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    train_acc, train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "    val_acc, val_loss = eval_model(model, test_loader, criterion, device)\n",
        "    print(f'Val loss {val_loss} accuracy {val_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCmCCLV2DZ8s",
        "outputId": "9c60c729-b882-424b-c86d-a047cee90ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Train loss 0.3571030331170526 accuracy 0.8864638783269962\n",
            "Val loss 0.14389702589341521 accuracy 0.9452554744525548\n",
            "Epoch 2/5\n",
            "Train loss 0.11972414164967074 accuracy 0.9565019011406845\n",
            "Val loss 0.1255292418600485 accuracy 0.9464720194647203\n",
            "Epoch 3/5\n",
            "Train loss 0.10118596702972722 accuracy 0.9606083650190114\n",
            "Val loss 0.11465022342846937 accuracy 0.9534671532846716\n",
            "Epoch 4/5\n",
            "Train loss 0.0938478569832116 accuracy 0.96212927756654\n",
            "Val loss 0.13675276894185656 accuracy 0.9504257907542579\n",
            "Epoch 5/5\n",
            "Train loss 0.08852013012146749 accuracy 0.9637262357414449\n",
            "Val loss 0.11177253656064441 accuracy 0.9540754257907543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = [\n",
        "    \"Говядина блочная 2 сорт в наличии ООО \\\"АгроСоюз\\\" реализует блочную говядину 2 сорт (80/20); Свободный объем 8 тонн Самовывоз или доставка. Все подробности по телефону.;\",\n",
        "    \"Куриная разделка Продам кур и куриную разделку гост и халяль по хорошей цене .Тел:;\",\n",
        "    \"Говяжью мукозу Продам говяжью мукозу в охл и замороженном виде. Есть объем.\"\n",
        "]\n",
        "\n",
        "test_dataset = TextDataset(\n",
        "    texts=test_texts,\n",
        "    labels=[0]*len(test_texts),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "model = model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for d in test_loader:\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "pred_labels = le.inverse_transform(predictions)\n",
        "for text, label in zip(test_texts, pred_labels):\n",
        "    print(f'Text: {text}\\nPredicted label: {label}\\n')\n"
      ],
      "metadata": {
        "id": "AwQJ7guWDe0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2526a07-cbd2-49f8-c0f8-028acbfe31c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Говядина блочная 2 сорт в наличии ООО \"АгроСоюз\" реализует блочную говядину 2 сорт (80/20); Свободный объем 8 тонн Самовывоз или доставка. Все подробности по телефону.;\n",
            "Predicted label: Говядина\n",
            "\n",
            "Text: Куриная разделка Продам кур и куриную разделку гост и халяль по хорошей цене .Тел:;\n",
            "Predicted label: Кура\n",
            "\n",
            "Text: Говяжью мукозу Продам говяжью мукозу в охл и замороженном виде. Есть объем.\n",
            "Predicted label: Говядина\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26C5nlmAG3NZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}